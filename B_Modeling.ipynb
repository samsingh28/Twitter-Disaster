{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('combined_scraped_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links\n",
    "df['text_no_links'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df['text_punct'] = df['text_no_links'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all other nonletters/nonspaces\n",
    "df['letters_only'] = df['text_no_links'].str.replace('[^a-zA-Z\\s]', '', case=False)\n",
    "df['letters_only'] = df['letters_only'].str.replace('\\\\n', ' ', case=False)\n",
    "df['letters_only'] = df['letters_only'].str.replace('\\\\xa0', ' ', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all text to lowercase\n",
    "df['clean_words'] = df['letters_only'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "df.to_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('./cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44472, 15)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate tokenizer and lemmatizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that \n",
    "def lemma(text):\n",
    "    tokens = tokenizer.tokenize(str(text))\n",
    "    lems = [lemmatizer.lemmatize(i) for i in tokens]\n",
    "    \n",
    "    return(\" \".join(lems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize tweets\n",
    "df['lems'] = df['clean_words'].apply(lambda x: lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congrats to cb trucking inc on the purchase of this utility flatbed if youre looking for a flatbed give u a call today and let u help you new and used trailer in'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lems'][68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train-test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y; perform train-test split\n",
    "X = df['lems']\n",
    "y = df['disaster_happened']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.530266\n",
       "1    0.469734\n",
       "Name: disaster_happened, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "df['disaster_happened'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Searching for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the types of models\n",
    "classifiers = [#LogisticRegression(), \n",
    "               #KNeighborsClassifier(),\n",
    "               RandomForestClassifier(), \n",
    "               #AdaBoostClassifier(), \n",
    "               #SVC()\n",
    "]\n",
    "\n",
    "names = [#'Logistic Reg',\n",
    "         #'kNN', \n",
    "         'Random Forest',\n",
    "         #'AdaBoost',\n",
    "         #'SVC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [ \n",
    "              { # Logistic Regression (Total: 40)\n",
    "#                  'vect__ngram_range': [(1, 1), (1, 2)], # 2\n",
    "#                  'clf__C': np.logspace(-5, 0, 10), # 10\n",
    "#                  'clf__penalty': ['l1', 'l2'], # 2\n",
    "              },\n",
    "                \n",
    "              { # kNN (Total: 20)\n",
    "#                  'vect__ngram_range': [(1, 1), (1, 2)], # 2\n",
    "#                  'clf__n_neighbors': range(5, 10), # 5\n",
    "#                  'clf__weights': ['uniform', 'distance'], # 2\n",
    "#                  'clf__n_jobs': [-2]\n",
    "              },\n",
    "                \n",
    "              { # Random Forest (Total: 20)\n",
    "                  #'vect__ngram_range': [(1, 1), (1, 2), (1, 3)], # 2\n",
    "                  'clf__n_estimators': range(5, 30), # 5\n",
    "                  'clf__criterion': ['gini', 'entropy'], # 2\n",
    "                  'clf__n_jobs': [-2]\n",
    "              },\n",
    "                \n",
    "              { # AdaBoost (Total: 6)\n",
    "#                  'vect__ngram_range': [(1, 1), (1, 2)], # 2\n",
    "#                  'clf__n_estimators': [10, 30, 50] # 3\n",
    "              },\n",
    "                \n",
    "              { # SVC (Total: 20)\n",
    "#                  'vect__ngram_range': [(1, 1), (1, 2)], # 2\n",
    "#                  'clf__C': range(1, 10), # 10\n",
    "#                  'clf__kernel': ['rbf'], # 1\n",
    "                  \n",
    "              }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ryan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/Ryan/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest:\n",
      "Train score: 0.9537744940571796\n",
      "Test score:  0.5887423174936292\n",
      "\n",
      " --- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for name, classifier, params in zip(names, classifiers, parameters):\n",
    "    clf_pipe = Pipeline([\n",
    "        ('vect', TfidfVectorizer(stop_words='english', max_features=30_000, ngram_range=(1, 3))),\n",
    "        ('clf', classifier),\n",
    "    ])\n",
    "    gs_clf = GridSearchCV(clf_pipe, param_grid=params, n_jobs=-1)\n",
    "    clf = gs_clf.fit(X_train, y_train)\n",
    "    \n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    if test_score > score:\n",
    "        score = test_score\n",
    "        best_mod = clf\n",
    "        \n",
    "    print(\"For {}:\".format(name))\n",
    "    print('Train score: {}'.format(clf.score(X_train, y_train)))\n",
    "    print('Test score:  {}'.format(test_score))\n",
    "    print('\\n --- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Optimizing Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9699967876646322, 0.5921900764503073)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# Build stop words list\n",
    "stop_words_1 = text.ENGLISH_STOP_WORDS.union(set(['ago',\n",
    " 'america',\n",
    " 'ball',\n",
    " 'birthday',\n",
    " 'cat',\n",
    " 'excited',\n",
    " 'family',\n",
    " 'glad',\n",
    " 'health',\n",
    " 'home',\n",
    " 'key',\n",
    " 'kid',\n",
    " 'labor',\n",
    " 'little',\n",
    " 'morning',\n",
    " 'return',\n",
    " 'rt',\n",
    " 'straight',\n",
    " 'walk',\n",
    " 'water',\n",
    " 'wednesday',\n",
    " 'weekend',\n",
    " 'wow',\n",
    " 'aint',\n",
    " 'better',\n",
    " 'brother',\n",
    " 'couple',\n",
    " 'drive',\n",
    " 'ga',\n",
    " 'georgia',\n",
    " 'great',\n",
    " 'hfd',\n",
    " 'home',\n",
    " 'im',\n",
    " 'leave',\n",
    " 'line',\n",
    " 'lo',\n",
    " 'mean',\n",
    " 'pick',\n",
    " 'sc',\n",
    " 'school',\n",
    " 'september',\n",
    " 'sign',\n",
    " 'sky',\n",
    " 'sound',\n",
    " 'south',\n",
    " 'starting',\n",
    " 'stop',\n",
    " 'support',\n",
    " 'true',\n",
    " 'tweet',\n",
    " 'wedding',\n",
    " 'west',\n",
    " 'win',\n",
    " 'wish',\n",
    " 'word',\n",
    " 'ya',\n",
    " 'york'\n",
    "]))\n",
    "\n",
    "\n",
    "# Instantiate TFIDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words_1, max_features = 30_000, ngram_range=(1, 4))\n",
    "\n",
    "# Fit and Transform train, Transform test\n",
    "train_features = tfidf.fit_transform(X_train)\n",
    "test_features = tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "# Instantiate Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42, )\n",
    "\n",
    "# Fit Random Forest to training set\n",
    "random_forest.fit(train_features, y_train)\n",
    "\n",
    "# Score train, test sets\n",
    "random_forest.score(train_features, y_train), random_forest.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "print(random_forest.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5175, 1926],\n",
       "       [3515, 2726]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Get predictions\n",
    "y_preds = random_forest.predict(test_features)\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
